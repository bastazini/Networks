##################################################
#Basic code for modularity and nestedness (weighted NODF) analyses in R
#
##################################################
# packages
require(bipartite)
require(igraph)
require(multigraph)

##import matrix
rede=read.csv(file.choose(), h=T, row.names = 1, sep=";")

plotweb(rede, text.rot = 90, col.high = "black", col.low = "grey50", arrow = "down")

## calculate observed WNODF and null models
#observed value
obs.nest =unlist(networklevel(rede, index="weighted NODF"))
#create null models
nulls = nullmodel(rede, N=1000, method=3)
#calculate wNODF for null models
null.nest = unlist(sapply(nulls, networklevel, index="weighted NODF"))
#save values in your folder
write.table(null.nest,"aninhamento.txt")
null.nest=as.matrix(null.nest)
#calculatenp-values and 95%CI
praw = sum(null.nest>=obs) / length(null.nest)
ifelse(praw >=0.5, 1-praw, praw)    # P-value
#95%CI
hist(as.vector(null.nest), col="grey", main="", xlim=c(min(obs, min(null.nest)), max(obs, max(null.nest))))
quantile(null.nest,prob=(c(0.025,0.5,0.975)))
abline(v=obs, col="red", lwd=2)




#modularity
obs.mod =unlist(computeModules(rede, method="Beckett", deep = FALSE, deleteOriginalFiles = TRUE,
               steps = 1000000, tolerance = 1e-10, experimental = FALSE, forceLPA=FALSE))

null.mod = unlist(sapply(nulls, computeModules,method="Beckett", deep = FALSE, deleteOriginalFiles = TRUE,
                                           steps = 1000000, tolerance = 1e-10, experimental = FALSE, forceLPA=FALSE))
null.mod[[1]]@likelihood
modularidade=sapply(null.mod, function(x){x@likelihood})
write.table(modularidade,"modularidade.txt")

pvalue = sum(modularidade>=obs) / length(modularidade)
ifelse(pvalue >=0.5, 1-pvalue, pvalue) 
# P-value
hist(modularidade, col="grey", main="", xlim=c(min(obs, min(modularidade)), max(obs, max(modularidade))))
quantile(modularidade,prob=(c(0.025,0.5,0.975)))
abline(v=obs, col="red", lwd=2)
